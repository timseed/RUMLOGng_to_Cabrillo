{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b40f55ae-f17f-421a-9840-cec4fcbc9fea",
   "metadata": {},
   "source": [
    "# Converting ADO to Cabrillo \n",
    "\n",
    "RUMLOGng is an excellent logger - I recently used it for some causual contesting in CQWW-2023 CW. I wanted to \n",
    "work some new countries - and by having my QSO history, made this quite easy.                                         \n",
    "However, I soon worked over 40 stations, so I needed to do 2 things\n",
    "\n",
    "  - Generate a Cabrillo file\n",
    "  - Update my QSO's via LOTW.\n",
    "\n",
    "Well the LOTW update is simple - the logger will do that. But to generate the Cabrillo file, needed a little work.\n",
    "\n",
    "## Extract the QSO's \n",
    "\n",
    "Just select the QSO's you want\n",
    "\n",
    "![Select](./select.png)\n",
    "\n",
    "After this choose \n",
    "\n",
    "![Export](./export.png)\n",
    "\n",
    "And save the ADO data. In this case I am using the filename **WW-2023**, RUMLogng will append the file type of *adx* to the file.\n",
    "\n",
    "## What is ADO data ??\n",
    "\n",
    "It essentially is XML, and if that means nothing to you - just think of it as *structured* text.\n",
    "\n",
    "## Why not ADIF ?\n",
    "Adif it seems does not export the frequency by default, it exports the Band. I did look at adif first, but this is why the ADO/ADX option was used.\n",
    "\n",
    "\n",
    "## Python/Programming \n",
    "\n",
    "**Danger** code ahead. \n",
    "\n",
    "I hope this is easy to read, please feel free to update/use as you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4694d56-6005-4cde-a3ad-62d2628644e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup # A standard Structured Text Parser in Python\n",
    "# Reading the data inside the xml\n",
    "# file to a variable under the name of data\n",
    "with open('WW-2023.adx', 'r') as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5984ffab-9316-4af1-8048-3ddd3e14ee97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passing the stored data inside\n",
    "# the beautifulsoup parser, storing\n",
    "# the returned object \n",
    "Bs_data = BeautifulSoup(data, \"xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125e8421-6e10-4083-9479-185d790ae5b1",
   "metadata": {},
   "source": [
    "# Tag  \n",
    "We can iterate through the data using find_all, we want to see 'RECORD' .... \n",
    "\n",
    "    for tag in Bs_data.find_all('RECORD'):\n",
    "       .. do something\n",
    "\n",
    "inside a 'tag' we can access a field by\n",
    "\n",
    "    tag.<FIELD> \n",
    "\n",
    "However this looks like this \n",
    "\n",
    "    <CALL>4W8X</CALL> \n",
    "\n",
    "To get just the call \n",
    "\n",
    "    tag.<FIELD>.text\n",
    "\n",
    "\n",
    "So to get the *Call* we do  \n",
    "\n",
    "    tag.<CALL>.text\n",
    "\n",
    "and we extract\n",
    "\n",
    "    '4W8X'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d09a457f-34cd-4cf5-9372-b674fffc7d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rec 3W9A\n",
      "Rec VK9XY\n",
      "Rec IR2Q\n",
      "Rec D4C\n",
      "Rec 4D3X\n",
      "Rec FW5N\n",
      "Rec E2X\n",
      "Rec LN8W\n",
      "Rec CR3A\n",
      "Rec S57K\n",
      "Rec P3AA\n",
      "Rec VR2T\n",
      "Rec HI3Y\n",
      "Rec P44W\n",
      "Rec C6AQQ\n",
      "Rec K6LL\n",
      "Rec XR1EW\n",
      "Rec CO8ZZ\n",
      "Rec PX2A\n",
      "Rec FY5KE\n",
      "Rec V31CQ\n",
      "Rec V26K\n",
      "Rec YR0K\n",
      "Rec 3B8M\n",
      "Rec VU2NXG\n",
      "Rec 9A1P\n",
      "Rec V85NPV\n",
      "Rec DF0HQ\n",
      "Rec HB9CA\n",
      "Rec CR3A\n",
      "Rec S58M\n",
      "Rec LZ9W\n",
      "Rec ER1KAA\n",
      "Rec 3W9A\n",
      "Rec EW5A\n",
      "Rec OM8CW\n",
      "Rec YT8A\n",
      "Rec OL9Z\n",
      "Rec S77HQ\n",
      "Rec 3B7M\n",
      "Rec DX8H\n",
      "Rec 5W1SA\n",
      "Rec 3B9KW\n",
      "Rec D4C\n",
      "Rec 3B8M\n",
      "Rec 3B8M\n",
      "Rec MU6P\n",
      "Rec EY7BJ\n",
      "Rec KP2M\n",
      "Rec LU8DPM\n",
      "Rec NP2J\n",
      "Rec CE3CT\n",
      "Rec 4D3X\n",
      "Rec KP2B\n",
      "Rec 3G6EW\n",
      "Rec OA4EA\n",
      "Rec CW5W\n",
      "Rec XE2AD\n",
      "Rec AA7A\n",
      "Rec XE1AY\n",
      "Rec PJ5J\n",
      "Rec VE7SZ\n",
      "Rec K6LL\n",
      "Rec HK3TU\n",
      "Rec K0FX\n",
      "Rec HQ9X\n",
      "Rec TI7W\n",
      "Rec V47T\n",
      "Rec K8R\n",
      "Rec W7WA\n",
      "Rec HQ9X\n",
      "Rec 4D3X\n",
      "Rec HG6N\n",
      "Rec OM2XW\n",
      "Rec TM7A\n",
      "Rec YT7A\n",
      "Rec UA0DAR\n",
      "Rec HL2BQG\n",
      "Rec AH2R\n",
      "Rec LX7I\n",
      "Rec OH0X\n",
      "Rec IM0HRP\n",
      "Rec XW4DX\n",
      "Rec EI6FR\n",
      "Rec DU3T\n",
      "Rec DU3T\n",
      "Rec LX7I\n",
      "Rec EX0M\n",
      "Rec 9M8YY\n",
      "Rec ER2QA\n",
      "Rec V85NPV\n",
      "Rec K8R\n",
      "Rec AH2R\n",
      "Rec ER1KAA\n",
      "Rec NP4Z\n",
      "Rec ZF1A\n",
      "Rec VK9XY\n",
      "Rec FY5KE\n",
      "Rec PJ2T\n",
      "Rec ZF5T\n",
      "Rec KH0W\n",
      "Rec WH2JA\n",
      "Rec P44W\n",
      "Rec PJ4K\n",
      "Rec TI7W\n",
      "Rec KP2M\n",
      "Rec HC2AD\n",
      "Rec PY4LH\n",
      "Rec 4W8X\n"
     ]
    }
   ],
   "source": [
    "# Lets see all the Callsigns in our ADX file, which has been parsed by BeautifulSoup\n",
    "for tag in Bs_data.find_all('RECORD'):\n",
    "    print(f\"Rec {tag.CALL.text}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531c53b9-f583-497d-be1a-037680b56b0b",
   "metadata": {},
   "source": [
    "# Fields \n",
    "\n",
    "We need the following fields. Please note that as CQWW using the *CQ Zone*, we have taken what the logger\n",
    "generated for us (on the assumption that the call was resolved correctly). If you were recording the Exchange \n",
    "say into the *notes* field. Then you would have to extract from that field and not the CQZ.\n",
    "\n",
    " - QSO_DATE\n",
    " - TIME_ON \n",
    " - FREQ \n",
    " - MODE \n",
    " - CALL \n",
    " - CQZ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5a8846d-f2d4-43be-b2d1-bd471ea3e75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields=['QSO_DATE','TIME_ON','FREQ','MODE','CALL','CQZ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "040a6798-5281-493b-ba3a-c5223e5ad4e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20231115'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag.find(fields[0]).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9130cae9-cc1a-46fe-9bf2-14c3698413f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are my internal definitions of Data for Cabrillo\n",
    "# It makes data munching a little easier.\n",
    "from hamcabrillo import cabrecord\n",
    "from hamcabrillo import LoadCab\n",
    "\n",
    "# You will need to edit this to your own needs.\n",
    "preamble='''\n",
    "START-OF-LOG: 3.0\n",
    "CALLSIGN: DV3A\n",
    "CONTEST: CQ-WW-CW\n",
    "CATEGORY-OPERATOR: SINGLE-OP\n",
    "CATEGORY-ASSISTED: ASSISTED\n",
    "CATEGORY-BAND: ALL\n",
    "CATEGORY-POWER: HIGH\n",
    "CATEGORY-MODE: CW\n",
    "CATEGORY-TRANSMITTER: ONE\n",
    "CERTIFICATE: YES\n",
    "CLAIMED-SCORE: 0\n",
    "CLUB:\n",
    "LOCATION: DX\n",
    "CREATED-BY: TimLog\n",
    "NAME: Tim Seed\n",
    "ADDRESS: 017 Arayat Magalang Rd\n",
    "ADDRESS: Purok 1\n",
    "ADDRESS: Brgy Arenas Arayat\n",
    "ADDRESS: 2012 Pampanga\n",
    "ADDRESS: Philippines \n",
    "OPERATORS: DU3TW\n",
    "SOAPBOX: Just S&P. Some JA and BY stations have VERY wide and noisy signals.\n",
    "SOAPBOX: Which is masking the DX stations, by their splatter.'''\n",
    "\n",
    "\n",
    "\n",
    "example='''QSO:  7007 CW 2016-11-26 0212 A45WG         599 21     LZ3ZZ         599 20     0\n",
    "QSO:  7012 CW 2016-11-26 0215 A45WG         599 21     IR2L          599 15     0\n",
    "QSO:  7013 CW 2016-11-26 0216 A45WG         599 21     SM5F          599 14     0\n",
    "QSO:  7016 CW 2016-11-26 0217 A45WG         599 21     UN9L          599 17     0'''\n",
    "\n",
    "postamble='END-OF-LOG:'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ab4aab4-6eea-4099-93e0-bb41d20e524d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please look at the file 'WW-2023.cbr' for the converted data\n"
     ]
    }
   ],
   "source": [
    "n=1\n",
    "recs=[]\n",
    "for tag in Bs_data.find_all('RECORD'):\n",
    "    rec=cabrecord(float(tag.FREQ.text),tag.MODE.text,tag.QSO_DATE.text+tag.TIME_ON.text,'DV3A','599','27',tag.CALL.text,'599',tag.CQZ.text,n)\n",
    "    recs.append(rec)\n",
    "\n",
    "with open('WW-2023.cbr','wt') as ofp:\n",
    "    ofp.write(f\"{preamble}\\n\")\n",
    "    #Used for Dev/Testing\n",
    "    #ofp.write(f\"{example}\\n\")\n",
    "    # For some strange reason - the export appears to be in reverse order.\n",
    "    # So we reverse the array\n",
    "    for r in reversed(recs):\n",
    "        ofp.write(f\"QSO: {r.freq*1000:5.0f} {r.mode:2s} {r.when[0:4]:4s}-{r.when[4:6]:2s}-{r.when[6:8]:2s} {r.when[8:12]:4s} {r.mycall:13s} {r.myrst:3s} {r.myexch:6s} {r.dxcall:13s} {r.dxrst:3s} {r.dxexch:6s} 0\\n\")\n",
    "    ofp.write(f\"{postamble}\")\n",
    "print(\"Please look at the file 'WW-2023.cbr' for the converted data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb0c71c-d5b8-46a7-a1d9-676cdf6bc8f7",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "RHUMLogng is a great logger, with a decent data interface. \n",
    "Manipulating its output is quite easy.\n",
    "\n",
    "\n",
    "Using the excellent site [http://tools.adventureradio.de/analyzer/](http://tools.adventureradio.de/analyzer/)\n",
    "\n",
    "This was my DX map \n",
    "\n",
    "![Dx.png](./Dx.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb2da5c-3147-40e7-93a6-94114612259d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pe310",
   "language": "python",
   "name": "pe310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
